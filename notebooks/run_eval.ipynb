{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Backtest Evaluation\n",
    "\n",
    "Run the `BacktestEngine` from the `eval` module and visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import ModelConfig\n",
    "from evaluate import BacktestEngine, BacktestVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: hicp_dk_dst (log_12m_diff)\n",
      "Features: 12\n",
      "Horizons: [1, 3, 6, 12, 18, 24]\n",
      "Backtest: expanding, 2010-01-01 to 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "CONFIG_PATH = Path('configs/spec.yaml')\n",
    "DATA_PATH = Path('data/example_data.parquet')\n",
    "\n",
    "config = ModelConfig.from_yaml(CONFIG_PATH)\n",
    "config.validate()\n",
    "\n",
    "print(f\"Target: {config.target.internal_series_name} ({config.target.transformation})\")\n",
    "print(f\"Features: {len(config.features)}\")\n",
    "print(f\"Horizons: {config.model.horizons}\")\n",
    "print(f\"Backtest: {config.backtest.method}, {config.backtest.start_date} to {config.backtest.end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = BacktestEngine(config, DATA_PATH)\n",
    "results = engine.run_backtest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics by horizon:\")\n",
    "results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.forecasts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = BacktestVisualizer(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_metrics_by_horizon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_forecast_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_actual_vs_forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fan chart for a specific forecast date\n",
    "forecast_date = results.forecast_dates[len(results.forecast_dates) // 2]\n",
    "print(f\"Showing fan chart for forecast date: {forecast_date.date()}\")\n",
    "viz.plot_forecast_fan_chart(forecast_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macrocast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
